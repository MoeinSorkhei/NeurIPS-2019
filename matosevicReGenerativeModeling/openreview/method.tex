\section{Method}
\label{sec:method}

\paragraph{Score estimation} \label{score_est} One major component of the proposed approach is direct estimation of the score $\nabla_{\mathbf{x}} \log p(\mathbf{x})$ using a neural network $s_{\bm{\theta}}(\mathbf{x})$, thus circumventing estimation of the data density $p(\mathbf{x})$. To this end, the theoretical objective $\frac{1}{2}\mathbb{E}_p\left[ || s_{\bm{\theta}}(\mathbf{x}) - \nabla_{\mathbf{x}} \log p(\mathbf{x})  ||^2_2 \right]$ can be reformulated in different ways to get two different loss functions, %for $s_{\bm{\theta}}$
sliced score matching (SSM) \citep{ssm} and denoising score matching (DSM) \citep{dsm}. SSM uses projections on random vectors $\mathbf{v} \sim p(\mathbf{v}) = \mathcal{N}(\mathbf{0}, \mathbf{I})$ and is given as
\begin{equation}
\mathbb{E}_{p_{\mathbf{v}}}\mathbb{E}_{p(\mathbf{x})}\left[ \mathbf{v}^{\text{T}}\nabla_{\mathbf{x}}s_{\bm{\theta}}(\mathbf{x})\mathbf{v} + \frac{1}{2}||s_{\bm{\theta}}(\mathbf{x}))||^2_2 \right].
\end{equation}
While the SSM loss is exact, it is slow to compute, so often in practice DSM loss is used instead. DSM loss estimates the score of density for perturbed data $ \mathbf{\tilde x}$ and is given as
\begin{equation}
\frac{1}{2} \mathbb{E}_{q_\sigma ( \mathbf{ \tilde x} | \mathbf{x}) p(\mathbf{x})} \left[ || s_{\bm{\theta}}( \mathbf{ \tilde x}) - \nabla_{\mathbf{\tilde x}} \log q_\sigma( \mathbf{ \tilde x} | \mathbf{x})  ||^2_2  \right],
\end{equation}
where $q_\sigma( \mathbf{ \tilde x} | \mathbf{x}) = \mathcal{N}(\mathbf{x}, \sigma^2\mathbf{I})$ in \cite{ncsn-paper}. Intuitively, a perturbed $\mathbf{\tilde x}$ should move us towards the original $\mathbf{x}$. In fact, it holds that $s^*_{\bm{\theta}}(\mathbf{x})  = \nabla_{\mathbf{x}} \log q_{\sigma} (\mathbf{x}) \approx \nabla_{\mathbf{x}} \log p(\mathbf{x})$ for $\sigma$ small enough so that $q_{\sigma}(\mathbf{x}) \approx p(\mathbf{x})$.

\paragraph{Sampling}\label{sampling} Using scores for generative modelling relies on sampling with Langevin dynamics. Namely, given a step size $\epsilon > 0$ and an initial value $\mathbf{\tilde x}_0$ we can, using only the score, compute $\mathbf{\tilde x}_t = \mathbf{\tilde x}_{t-1} + \frac{\epsilon}{2}\nabla_{\mathbf{x}}s^*_{\bm{\theta}}(\mathbf{\tilde x}_{t-1})  + \sqrt{\epsilon}\ \mathbf{z}_t$, where $\mathbf{z}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$, for $T$ steps. It has been shown that under some regularity conditions $\mathbf{\tilde x}_T$ is an exact sample from $p(\mathbf{x})$ as $T \to \infty$ and $\epsilon \to 0$ \cite{Welling:2011:BLV:3104482.3104568}.


Unfortunately, direct implementation of the proposed framework usually suffers from two major issues, which the authors attribute to the manifold hypothesis and low-density regions of $p(\mathbf{x})$. 

\paragraph{Manifold hypothesis} For most natural images, the manifold hypothesis states that the intrinsic dimensionality of $\mathbf{x}$ has a support in $\mathbb{R}^M \subset \mathbb{R}^D$, where $M \ll D$. As a consequence, a score (gradient) taken in $\mathbb{R}^D$ is not going to be defined in $\mathbb{R}^M$. We will demonstrate the effects of this on training the score network by replicating a toy example from \cite{ncsn-paper} (\autoref{sec:repr-of-toy}).

\paragraph{Low-density regions} A negative effect of low-density regions concerns both score estimation and sampling. 
Firstly, the number of samples from low-density regions of $p(\mathbf{x})$ is not sufficient to accurately estimate the loss (i.e. scores) during training. Following \cite{ncsn-paper}, we visualise this by comparing analytic and estimated scores of a mixture of two Gaussians with near-zero density regions between the modes (\autoref{sec:repr-of-toy}).
Regarding sampling, Langevin dynamics require an infeasible number of iterations in traversing these regions to obtain good mixing. We successfully reproduce an experiment showing this on the same GMM (\autoref{sec:repr-of-toy}).

\paragraph{Proposed solutions}
Firstly, to remedy the negative implications of the manifold hypothesis, \citet{ncsn-paper} suggest adding Gaussian noise to data. Since the noise is defined in $\mathbb{R}^D$, this results in gradients being defined everywhere. Secondly, the authors observe that adding large noise also helps to fill in the low-density regions, hence improving the score estimation. Thirdly, while large noise helps during the training, it is not favourable for sampling. To address this issue, they propose obtaining a sample by iteratively generating from distributions of perturbed data $\{q_{\sigma_i}\}_{i=1}^L$ parameterised by a decreasing geometric sequence $\{\sigma_i\}_{i=1}^L$ of noise levels. This way one utilises the benefits of large noise to avoid low-density regions, but also gradually transitions to small noise where the perturbed data distribution is indistinguishable from $p(\mathbf{x})$. In practice, this requires only a small modification to Langevin dynamics described in \autoref{sampling} by embedding it into iterations over noise levels\footnote{Note that $\mathbf{x}_{\sigma_i} \sim q_{\sigma_i}$ is used to initialise sampling from $q_{\sigma_{i+1}}$. Intuitively, $\mathbf{x}_{\sigma_i}$ comes from a high-density region of $q_{\sigma_i}$ and since $q_{\sigma_i}$ and $q_{\sigma_{i+1}}$ are similar, $\mathbf{x}_{\sigma_i}$ is also in a high-density region of $q_{\sigma_{i+1}}$.} and multiplying $\epsilon$ by a factor of ${\sigma_i}^2/{\sigma_L}^2$. To employ this procedure, a single score network is trained with the total loss $\mathcal{L}(\bm{\theta}; \{\sigma_l\}_{l=1}^L) = \frac{1}{L}\sum_{l=1}^L \lambda(\sigma_l) \ell (\bm{\theta}; \sigma_i)$, where $\ell(\cdot)$ is a DSM loss\footnote{Well-motivated since we are now estimating the score of perturbed data.}, and $\lambda(\cdot)$ a parameter regulating that none of the individual loss terms dominates ($\sigma_i^2$ in \cite{ncsn-paper}).

