@inproceedings{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@incollection{NIPS2018_8044,
title = {Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion},
author = {Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {8224--8234},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8044-sample-efficient-reinforcement-learning-with-stochastic-ensemble-value-expansion.pdf}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@misc{orrivlinreview,
  author       = {Or Rivlin},
  title        = {Model Based Policy Optimization: Reviewing recent advances in model-based reinforcement learning},
  year         = {2019},
  howpublished = {https://towardsdatascience.com/model-based-policy-optimization-d7e099c73d8},
  note         = {Accessed Aug 1, 2019}
}

@incollection{NIPS2018_7725,
title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {4754--4765},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7725-deep-reinforcement-learning-in-a-handful-of-trials-using-probabilistic-dynamics-models.pdf}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@misc{sac_pytorch,
    author       = {Pranjal Tandon},
    title        = {pytorch-soft-actor-critic},
    howpublished = {https://github.com/pranz24/pytorch-soft-actor-critic}
    }

@article{luo2018algorithmic,
  title={Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}

@article{feinberg2018model,
  title={Model-based value estimation for efficient model-free reinforcement learning},
  author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
  journal={arXiv preprint arXiv:1803.00101},
  year={2018}
}

